{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Missing Data\n",
    "Missing Data can occur when no information is provided for one or more items or for a whole unit. Missing Data is a very big problem in real life scenario. Missing Data can also refer to as NA(Not Available) values in pandas. In DataFrame sometimes many datasets simply arrive with missing data, either because it exists and was not collected or it never existed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas missing data is represented by two value:\n",
    "\n",
    "    •\tNone: None is a Python singleton object that is often used for missing data in Python code.\n",
    "    •\tNaN : NaN (an acronym for Not a Number), is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation\n",
    "\n",
    "Pandas treat `None` and `NaN` as essentially interchangeable for indicating missing or null values. To facilitate this convention, there are several useful functions for detecting, removing, and replacing null values in Pandas DataFrame :\n",
    "\n",
    "    •\tisnull()\n",
    "    •\tnotnull()\n",
    "    •\tdropna()\n",
    "    •\tfillna()\n",
    "    •\treplace()\n",
    "    •\tinterpolate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategies to handle missing data.\n",
    "**Deleting Rows**\n",
    "\n",
    "This method commonly used to handle the null values. Here, we either delete a particular row if it has a null value for a particular feature and a particular column if it has more than 70-75% of missing values. This method is advised only when there are enough samples in the data set. One has to make sure that after we have deleted the data, there is no addition of bias. Removing the data will lead to loss of information which will not give the expected results while predicting the output.\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "    Complete removal of data with missing values results in robust and highly accurate model\n",
    "    Deleting a particular row or a column with no specific information is better, since it does not have a high weightage\n",
    "    \n",
    "**Cons**:\n",
    "\n",
    "    Loss of information and data\n",
    "    Works poorly if the percentage of missing values is high (say 30%), compared to the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing With Mean/Median/Mode\n",
    "This strategy can be applied on a feature which has numeric data. We can calculate the mean, median or mode of the feature and replace it with the missing values. This is an approximation which can add variance to the data set. But the loss of the data can be negated by this method which yields better results compared to removal of rows and columns. Replacing with the above three approximations are a statistical approach of handling the missing values. This method is also called as leaking the data while training. Another way is to approximate it with the deviation of neighbouring values. This works better if the data is linear.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "\n",
    "    This is a better approach when the data size is small\n",
    "    It can prevent data loss which results in removal of the rows and columns\n",
    "**Cons**:\n",
    "\n",
    "    Imputing the approximations add variance and bias\n",
    "    Works poorly compared to other multiple-imputations method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning An Unique Category\n",
    "A categorical feature will have a definite number of possibilities, such as gender, for example. Since they have a definite number of classes, we can assign another class for the missing values. Here, the features can be replaced with a new category, (i.e U for ‘unknown’). This strategy will add more information into the dataset which will result in the change of variance. Since they are categorical, we need to find one hot encoding to convert it to a numeric form for the algorithm to understand it.\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "    Less possibilities with one extra category, resulting in low variance after one hot encoding — since it is categorical\n",
    "    Negates the loss of data by adding an unique category\n",
    "**Cons**:\n",
    "\n",
    "    Adds less variance\n",
    "    Adds another feature to the model while encoding, which may result in poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting The Missing Values\n",
    "Using the features which do not have missing values, we can predict the nulls with the help of a machine learning algorithm. This method may result in better accuracy, unless a missing value is expected to have a very high variance. We will use linear regression to replace the nulls in the feature, using other available features. One can experiment with different algorithms and check which gives the best accuracy instead of sticking to a single algorithm.\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "    Imputing the missing variable is an improvement as long as the bias from the same is smaller than the omitted variable bias\n",
    "    Yields unbiased estimates of the model parameters\n",
    "**Cons**:\n",
    "\n",
    "    Bias also arises when an incomplete conditioning set is used for a categorical variable\n",
    "    Considered only as a proxy for the true values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Algorithms Which Support Missing Values\n",
    "KNN is a machine learning algorithm which works on the principle of distance measure. This algorithm can be used when there are nulls present in the dataset. While the algorithm is applied, KNN considers the missing values by taking the majority of the K nearest values.\n",
    "\n",
    "Unfortunately, the SciKit Learn library for the K – Nearest Neighbour algorithm in Python does not support the presence of the missing values.\n",
    "\n",
    "Another algorithm which can be used here is RandomForest. This model produces a robust result because it works well on non-linear and the categorical data. It adapts to the data structure taking into consideration of the high variance or the bias, producing better results on large datasets.\n",
    "\n",
    "**Pros**:\n",
    "\n",
    "    Does not require creation of a predictive model for each attribute with missing data in the dataset\n",
    "    Correlation of the data is neglected\n",
    "**Cons**:\n",
    "\n",
    "    Is a very time consuming process and it can be critical in data mining where large databases are being extracted\n",
    "    Choice of distance functions can be Euclidean, Manhattan etc. which is do not yield a robust result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "    How do you handle missing or corrupted data in a dataset?\n",
    "    A)Drop missing rows or columns\n",
    "    B)Replace missing values with mean/median/mode\n",
    "    C)Assign a unique category to missing values\n",
    "    D)All of the above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
