{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "Boosting is primarily used to reduce the bias and variance in a supervised learning technique. It refers to the family of an algorithm that converts weak learners (base learner) to strong learners. The weak learner is the classifiers that are correct only up to a small extent with the actual classification, while the strong learners are the classifiers that are well correlated with the actual classification. \n",
    "\n",
    "Boosting will run a model, recognize the weak learners in the first model, and then attempt to strengthen those learners n the next model. Few famous techniques of Boosting are (1)AdaBoost and (2) Gradient Boosting 3)XGBoost 4)LightGBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of Boosting\n",
    "    •\tIt is one of the most successful techniques in solving the two-class classification problems.\n",
    "    •\tIt is good at handling the missing data.\n",
    "    \n",
    "#### Disadvantages of Boosting\n",
    "\n",
    "    •\tBoosting is hard to implement in real-time due to the increased complexity of the algorithm.\n",
    "    •\tHigh flexibility of this techniques results in a multiple number of parameters than have a direct effect on the behavior of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
